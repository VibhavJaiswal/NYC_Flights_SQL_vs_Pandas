{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c96e1d8",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Data manipulation is a fundamental aspect of data analysis, and the choice of tools can significantly impact the efficiency and accuracy of the analysis. This notebook explores various data manipulation tasks using both SQL and pandas, two widely used tools in the field of data science. The tasks cover a spectrum of operations, ranging from simple queries to complex joins and aggregations. The primary goal is to showcase the versatility of SQL and pandas in handling diverse data manipulation scenarios.\n",
    "\n",
    "In each task, we compare the results obtained using SQL and pandas, ensuring consistency between the two approaches. The dataset under consideration includes information about flights, planes, airlines, airports, and weather. By addressing each subtask and providing visualizations where applicable, we aim to demonstrate not only the technical proficiency in using SQL and pandas but also the practical considerations in choosing the right tool for specific data analysis tasks.\n",
    "\n",
    "This report serves as a comprehensive guide to understanding the implementation of various data manipulation operations and the nuances involved in the SQL and pandas approaches. Through this exploration, we gain insights into the strengths and limitations of each tool, empowering data scientists to make informed decisions when working with diverse datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9381ba",
   "metadata": {},
   "source": [
    "### Loading Data into SQLite Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e381812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26130"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import gzip\n",
    "\n",
    "# Establish a connection with a new SQLite database\n",
    "conn = sqlite3.connect('nycflights13.db')\n",
    "\n",
    "# Load CSV files into the SQLite database with skipping commented lines\n",
    "flights = pd.read_csv('nycflights13_flights.csv.gz', compression='gzip', comment='#')\n",
    "flights.to_sql('flights', conn, index=False, if_exists='replace')\n",
    "\n",
    "airlines = pd.read_csv('nycflights13_airlines.csv.gz', compression='gzip', comment='#')\n",
    "airlines.to_sql('airlines', conn, index=False, if_exists='replace')\n",
    "\n",
    "airports = pd.read_csv('nycflights13_airports.csv.gz', compression='gzip', comment='#')\n",
    "airports.to_sql('airports', conn, index=False, if_exists='replace')\n",
    "\n",
    "planes = pd.read_csv('nycflights13_planes.csv.gz', compression='gzip', comment='#')\n",
    "planes.to_sql('planes', conn, index=False, if_exists='replace')\n",
    "\n",
    "weather = pd.read_csv('nycflights13_weather.csv.gz', compression='gzip', comment='#')\n",
    "weather.to_sql('weather', conn, index=False, if_exists='replace')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a88925",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "This code chunk establishes a connection to a new SQLite database and loads various CSV files into the corresponding tables in the database.\n",
    "\n",
    "Summary/Discussion:\n",
    "The dataset is now available in an SQLite database, making it accessible for both SQL and pandas manipulations in subsequent tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcd5a86",
   "metadata": {},
   "source": [
    "### 1. SELECT DISTINCT engine FROM planes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60aca091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalent Pandas Code\n",
    "task1_sql = pd.read_sql_query(\"SELECT DISTINCT engine FROM planes\", conn)\n",
    "\n",
    "# Sort both DataFrames\n",
    "task1_sql_sorted = task1_sql.sort_values(by='engine').reset_index(drop=True)\n",
    "\n",
    "# solution using pandas — without SQL\n",
    "task1_my = planes[['engine']].drop_duplicates()\n",
    "\n",
    "# Sort both DataFrames\n",
    "task1_my_sorted = task1_my.sort_values(by='engine').reset_index(drop=True)\n",
    "\n",
    "# Perform the equality check\n",
    "pd.testing.assert_frame_equal(task1_sql_sorted, task1_my_sorted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7d8a09",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "In this task, we compare the distinct engine values obtained using SQL and pandas. The SQL query selects unique engine values from the 'planes' table, while the pandas solution achieves the same by selecting the 'engine' column and dropping duplicates.\n",
    "\n",
    "Summary/Discussion:\n",
    "The results from both SQL and pandas are equivalent, as confirmed by the assertion check. This task serves as a baseline for comparing the accuracy and consistency of SQL and pandas operations throughout the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a7f2c7",
   "metadata": {},
   "source": [
    "### 2. SELECT DISTINCT type, engine FROM planes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf5316fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalent Pandas Code\n",
    "task2_sql = pd.read_sql_query(\"SELECT DISTINCT type, engine FROM planes\", conn)\n",
    "\n",
    "# Sort both DataFrames\n",
    "task2_sql_sorted = task2_sql.sort_values(by=['type', 'engine']).reset_index(drop=True)\n",
    "\n",
    "# solution using pandas — without SQL\n",
    "task2_my = planes[['type', 'engine']].drop_duplicates()\n",
    "\n",
    "# Sort both DataFrames\n",
    "task2_my_sorted = task2_my.sort_values(by=['type', 'engine']).reset_index(drop=True)\n",
    "\n",
    "# Perform the equality check\n",
    "pd.testing.assert_frame_equal(task2_sql_sorted, task2_my_sorted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce006914",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "This task involves comparing distinct combinations of 'type' and 'engine' obtained using SQL and pandas. The SQL query selects unique pairs of 'type' and 'engine' from the 'planes' table, while the pandas solution achieves the same by selecting the corresponding columns and dropping duplicates.\n",
    "\n",
    "Summary/Discussion:\n",
    "The results from both SQL and pandas are consistent, as confirmed by the assertion check. This task demonstrates the capability of pandas to replicate distinct values from multiple columns in SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6404e89f",
   "metadata": {},
   "source": [
    "### 3. SELECT COUNT(*), engine FROM planes GROUP BY engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59ee14cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalent Pandas Code\n",
    "task3_sql = pd.read_sql_query(\"SELECT COUNT(*), engine FROM planes GROUP BY engine\", conn)\n",
    "\n",
    "# Sort both DataFrames\n",
    "task3_sql_sorted = task3_sql.sort_values(by='engine').reset_index(drop=True)\n",
    "\n",
    "# solution using pandas — without SQL\n",
    "task3_my = planes.groupby('engine').size().reset_index(name='COUNT(*)')[['COUNT(*)', 'engine']]  # Adjust column order\n",
    "\n",
    "# Sort both DataFrames\n",
    "task3_my_sorted = task3_my.sort_values(by='engine').reset_index(drop=True)\n",
    "\n",
    "# Perform the equality check\n",
    "pd.testing.assert_frame_equal(task3_sql_sorted, task3_my_sorted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ecd137",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "In this task, the goal is to compare the counts of occurrences for each 'engine' obtained through SQL and pandas. The SQL query counts the number of rows for each 'engine' group in the 'planes' table, and the pandas solution achieves the same using the groupby and size functions.\n",
    "\n",
    "Summary/Discussion:\n",
    "The results from both SQL and pandas match, indicating that the count aggregation is consistent between the two approaches. This task illustrates how pandas can be employed to perform group-wise operations akin to SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fa6cf0",
   "metadata": {},
   "source": [
    "### 4. SELECT COUNT(*), engine, type FROM planes\n",
    "### GROUP BY engine, type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "032afb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalent Pandas Code\n",
    "task4_sql = pd.read_sql_query(\"SELECT COUNT(*), engine, type FROM planes GROUP BY engine, type\", conn)\n",
    "\n",
    "# Sort both DataFrames\n",
    "task4_sql_sorted = task4_sql.sort_values(by=['engine', 'type']).reset_index(drop=True)\n",
    "\n",
    "# solution using pandas — without SQL\n",
    "task4_my = planes.groupby(['engine', 'type']).size().reset_index(name='COUNT(*)')\n",
    "\n",
    "# Reorder columns in task4_my to match task4_sql\n",
    "task4_my = task4_my[['COUNT(*)', 'engine', 'type']]\n",
    "\n",
    "# Sort both DataFrames\n",
    "task4_my_sorted = task4_my.sort_values(by=['engine', 'type']).reset_index(drop=True)\n",
    "\n",
    "# Perform the equality check\n",
    "pd.testing.assert_frame_equal(task4_sql_sorted, task4_my_sorted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6386b9e3",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "This task involves counting the occurrences for each combination of 'engine' and 'type' in the 'planes' dataset using both SQL and pandas. The SQL query groups by both columns and counts the number of rows in each group. The pandas solution achieves the same using groupby and size functions.\n",
    "\n",
    "Summary/Discussion:\n",
    "The results from both SQL and pandas match, demonstrating consistency in counting occurrences for multiple columns across the two approaches. This showcases the versatility of pandas for such group-wise operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8416a95e",
   "metadata": {},
   "source": [
    "### 5. SELECT MIN(year), AVG(year), MAX(year), engine, manufacturer\n",
    "### FROM planes\n",
    "### GROUP BY engine, manufacturer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95ea03fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the required statistics using pandas\n",
    "task5_my = planes.groupby(['engine', 'manufacturer']).agg({'year': ['min', 'mean', 'max']}).reset_index()\n",
    "\n",
    "# Rename the columns for consistency with SQL\n",
    "task5_my.columns = ['engine', 'manufacturer', 'min_year', 'avg_year', 'max_year']\n",
    "\n",
    "# Sort both DataFrames\n",
    "task5_sql_sorted = pd.read_sql_query(\"\"\"\n",
    "    SELECT MIN(year) AS min_year, AVG(year) AS avg_year, MAX(year) AS max_year, engine, manufacturer\n",
    "    FROM planes\n",
    "    GROUP BY engine, manufacturer;\n",
    "\"\"\", conn).sort_values(by=['engine', 'manufacturer']).reset_index(drop=True)\n",
    "\n",
    "task5_my_sorted = task5_my.sort_values(by=['engine', 'manufacturer']).reset_index(drop=True)\n",
    "\n",
    "# Perform the equality check\n",
    "pd.testing.assert_frame_equal(task5_sql_sorted, task5_my_sorted, check_like=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7880d5e",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "Task 5 involves calculating the minimum, average, and maximum values of the 'year' column for each combination of 'engine' and 'manufacturer' in the 'planes' dataset. Both SQL and pandas are used for this calculation.\n",
    "\n",
    "Summary/Discussion:\n",
    "The results from both SQL and pandas match, demonstrating consistency in computing summary statistics for multiple columns across the two approaches. The check_like parameter ensures the comparison considers potential numerical variations. This task highlights pandas' ability to handle complex aggregations effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a177c1",
   "metadata": {},
   "source": [
    "### 6. SELECT * FROM planes WHERE speed IS NOT NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae6021a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows in the 'planes' DataFrame where 'speed' is not null\n",
    "task6_my = planes[planes['speed'].notnull()]\n",
    "\n",
    "# Reset index for consistent comparison\n",
    "task6_my.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Sort both DataFrames\n",
    "task6_sql_sorted = pd.read_sql_query(\"\"\"\n",
    "    SELECT *\n",
    "    FROM planes\n",
    "    WHERE speed IS NOT NULL;\n",
    "\"\"\", conn).sort_values(by=['speed']).reset_index(drop=True)\n",
    "\n",
    "task6_my_sorted = task6_my.sort_values(by=['speed']).reset_index(drop=True)\n",
    "\n",
    "# Perform the equality check\n",
    "pd.testing.assert_frame_equal(task6_sql_sorted, task6_my_sorted, check_like=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9676c847",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "Task 6 involves filtering rows in the 'planes' dataset where the 'speed' column is not null. Both pandas and SQL are used for this operation.\n",
    "\n",
    "Summary/Discussion:\n",
    "The results from both SQL and pandas match, indicating that the filtering operation has been performed consistently in both cases. The check_like parameter ensures a flexible comparison, accounting for potential numerical variations. This task demonstrates the equivalence of filtering operations in pandas and SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6707a0",
   "metadata": {},
   "source": [
    "### 7. SELECT tailnum FROM planes\n",
    "### WHERE seats BETWEEN 150 AND 210 AND year >= 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86476f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows in the 'planes' DataFrame based on conditions\n",
    "task7_my = planes[(planes['seats'].between(150, 210)) & (planes['year'] >= 2011)][['tailnum']]\n",
    "\n",
    "# Reset index for consistent comparison\n",
    "task7_my.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Sort both DataFrames\n",
    "task7_sql_sorted = pd.read_sql_query(\"\"\"\n",
    "    SELECT tailnum\n",
    "    FROM planes\n",
    "    WHERE seats BETWEEN 150 AND 210 AND year >= 2011;\n",
    "\"\"\", conn).sort_values(by=['tailnum']).reset_index(drop=True)\n",
    "\n",
    "task7_my_sorted = task7_my.sort_values(by=['tailnum']).reset_index(drop=True)\n",
    "\n",
    "# Perform the equality check\n",
    "pd.testing.assert_frame_equal(task7_sql_sorted, task7_my_sorted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531b5584",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "Task 7 involves filtering rows in the 'planes' dataset based on specified conditions related to 'seats' and 'year'. Both pandas and SQL are used for this operation.\n",
    "\n",
    "Summary/Discussion:\n",
    "The results from both SQL and pandas match, indicating that the filtering operation has been performed consistently in both cases. This task demonstrates the equivalence of complex filtering conditions in pandas and SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb084a48",
   "metadata": {},
   "source": [
    "### 8. SELECT tailnum, manufacturer, seats FROM planes\n",
    "### WHERE manufacturer IN (\"BOEING\", \"AIRBUS\", \"EMBRAER\") AND seats>390"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4903f0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows in the 'planes' DataFrame based on conditions\n",
    "manufacturers = [\"BOEING\", \"AIRBUS\", \"EMBRAER\"]\n",
    "task8_my = planes[(planes['manufacturer'].isin(manufacturers)) & (planes['seats'] > 390)][['tailnum', 'manufacturer', 'seats']]\n",
    "\n",
    "# Reset index for consistent comparison\n",
    "task8_my.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Sort both DataFrames\n",
    "task8_sql_sorted = pd.read_sql_query(\"\"\"\n",
    "    SELECT tailnum, manufacturer, seats\n",
    "    FROM planes\n",
    "    WHERE manufacturer IN (\"BOEING\", \"AIRBUS\", \"EMBRAER\") AND seats > 390;\n",
    "\"\"\", conn).sort_values(by=['tailnum']).reset_index(drop=True)\n",
    "\n",
    "task8_my_sorted = task8_my.sort_values(by=['tailnum']).reset_index(drop=True)\n",
    "\n",
    "# Perform the equality check\n",
    "pd.testing.assert_frame_equal(task8_sql_sorted, task8_my_sorted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2449d0bf",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "Task 8 involves filtering rows in the 'planes' dataset based on multiple conditions, including a list of manufacturers and a minimum number of seats. Both pandas and SQL are used for this operation.\n",
    "\n",
    "Summary/Discussion:\n",
    "The results from both SQL and pandas match, indicating that the filtering operation has been performed consistently in both cases. This task demonstrates the equivalence of complex filtering conditions with multiple criteria in pandas and SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c010bd4",
   "metadata": {},
   "source": [
    "### 9. SELECT DISTINCT year, seats FROM planes\n",
    "### WHERE year >= 2012 ORDER BY year ASC, seats DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "160c71ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows in the 'planes' DataFrame based on the condition\n",
    "task9_my = planes[planes['year'] >= 2012][['year', 'seats']]\n",
    "\n",
    "# Remove duplicate rows to simulate DISTINCT\n",
    "task9_my.drop_duplicates(inplace=True)\n",
    "\n",
    "# Sort the DataFrame based on 'year' in ascending order and 'seats' in descending order\n",
    "task9_my.sort_values(by=['year', 'seats'], ascending=[True, False], inplace=True)\n",
    "\n",
    "# Reset index for consistent comparison\n",
    "task9_my.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Sort the 'planes' DataFrame from SQL query\n",
    "task9_sql_sorted = pd.read_sql_query(\"\"\"\n",
    "    SELECT DISTINCT year, seats\n",
    "    FROM planes\n",
    "    WHERE year >= 2012\n",
    "    ORDER BY year ASC, seats DESC;\n",
    "\"\"\", conn).sort_values(by=['year', 'seats'], ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "# Perform the equality check\n",
    "pd.testing.assert_frame_equal(task9_sql_sorted, task9_my)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5517d2",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "Task 9 involves filtering rows in the 'planes' dataset based on a condition (year >= 2012) and selecting specific columns ('year' and 'seats'). Both pandas and SQL are used for this operation.\n",
    "\n",
    "Summary/Discussion:\n",
    "The results from both SQL and pandas match, indicating that the filtering and column selection operations have been performed consistently in both cases. This task demonstrates the equivalence of filtering rows, selecting columns, and using DISTINCT in pandas and SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68f304b",
   "metadata": {},
   "source": [
    "### 10. SELECT DISTINCT year, seats FROM planes\n",
    "### WHERE year >= 2012 ORDER BY seats DESC, year ASC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c63f004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows in the 'planes' DataFrame based on the condition\n",
    "task10_my = planes[planes['year'] >= 2012][['year', 'seats']]\n",
    "\n",
    "# Remove duplicate rows to simulate DISTINCT\n",
    "task10_my.drop_duplicates(inplace=True)\n",
    "\n",
    "# Sort the DataFrame based on 'seats' in descending order and 'year' in ascending order\n",
    "task10_my.sort_values(by=['seats', 'year'], ascending=[False, True], inplace=True)\n",
    "\n",
    "# Reset index for consistent comparison\n",
    "task10_my.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Sort the 'planes' DataFrame from SQL query\n",
    "task10_sql_sorted = pd.read_sql_query(\"\"\"\n",
    "    SELECT DISTINCT year, seats\n",
    "    FROM planes\n",
    "    WHERE year >= 2012\n",
    "    ORDER BY seats DESC, year ASC;\n",
    "\"\"\", conn).sort_values(by=['seats', 'year'], ascending=[False, True]).reset_index(drop=True)\n",
    "\n",
    "# Perform the equality check\n",
    "pd.testing.assert_frame_equal(task10_sql_sorted, task10_my)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e112111e",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "Task 10 involves filtering rows in the 'planes' dataset based on a condition (year >= 2012), selecting specific columns ('year' and 'seats'), removing duplicates, and sorting the DataFrame based on 'seats' in descending order and 'year' in ascending order. Both pandas and SQL are used for this operation.\n",
    "\n",
    "Summary/Discussion:\n",
    "The results from both SQL and pandas match, indicating that the filtering, column selection, duplicate removal, and sorting operations have been performed consistently in both cases. This task demonstrates the equivalence of these operations in pandas and SQL.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5370046",
   "metadata": {},
   "source": [
    "### 11. SELECT manufacturer, COUNT(*) FROM planes\n",
    "### WHERE seats > 200 GROUP BY manufacturer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6c0683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows in the 'planes' DataFrame based on the condition\n",
    "task11_my = planes[planes['seats'] > 200]\n",
    "\n",
    "# Group by 'manufacturer' and count the occurrences\n",
    "task11_my = task11_my.groupby('manufacturer').size().reset_index(name='count')\n",
    "\n",
    "# Sort the DataFrame based on 'count' in descending order and 'manufacturer' in ascending order\n",
    "task11_my.sort_values(by=['count', 'manufacturer'], ascending=[False, True], inplace=True)\n",
    "\n",
    "# Reset index for consistent comparison\n",
    "task11_my.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Sort the 'planes' DataFrame from SQL query\n",
    "task11_sql_sorted = pd.read_sql_query(\"\"\"\n",
    "    SELECT manufacturer, COUNT(*) AS count\n",
    "    FROM planes\n",
    "    WHERE seats > 200\n",
    "    GROUP BY manufacturer;\n",
    "\"\"\", conn).sort_values(by=['count', 'manufacturer'], ascending=[False, True]).reset_index(drop=True)\n",
    "\n",
    "# Perform the equality check\n",
    "pd.testing.assert_frame_equal(task11_sql_sorted, task11_my)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ed6e91",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "Task 11 involves filtering rows in the 'planes' dataset based on a condition (seats > 200), grouping by 'manufacturer,' counting occurrences, and sorting the result by count in descending order and 'manufacturer' in ascending order. Both pandas and SQL are used for this operation.\n",
    "\n",
    "Summary/Discussion:\n",
    "The results from both SQL and pandas match, indicating that the filtering, grouping, counting, and sorting operations have been performed consistently in both cases. This task demonstrates the equivalence of these operations in pandas and SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ce7ded",
   "metadata": {},
   "source": [
    "### 12. SELECT manufacturer, COUNT(*) FROM planes\n",
    "### GROUP BY manufacturer HAVING COUNT(*) > 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08d6540c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'manufacturer' and count the occurrences\n",
    "task12_my = planes.groupby('manufacturer').size().reset_index(name='count')\n",
    "\n",
    "# Filter rows where the count is greater than 10\n",
    "task12_my = task12_my[task12_my['count'] > 10]\n",
    "\n",
    "# Sort the DataFrame based on 'count' in descending order and 'manufacturer' in ascending order\n",
    "task12_my.sort_values(by=['count', 'manufacturer'], ascending=[False, True], inplace=True)\n",
    "\n",
    "# Reset index for consistent comparison\n",
    "task12_my.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Sort the 'planes' DataFrame from SQL query\n",
    "task12_sql_sorted = pd.read_sql_query(\"\"\"\n",
    "    SELECT manufacturer, COUNT(*) AS count\n",
    "    FROM planes\n",
    "    GROUP BY manufacturer\n",
    "    HAVING COUNT(*) > 10;\n",
    "\"\"\", conn).sort_values(by=['count', 'manufacturer'], ascending=[False, True]).reset_index(drop=True)\n",
    "\n",
    "# Perform the equality check\n",
    "pd.testing.assert_frame_equal(task12_sql_sorted, task12_my)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53864fa6",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "Task 12 involves grouping the 'planes' dataset by 'manufacturer,' counting occurrences, filtering rows where the count is greater than 10, and sorting the result by count in descending order and 'manufacturer' in ascending order. Both pandas and SQL are used for this operation.\n",
    "\n",
    "Summary/Discussion:\n",
    "The results from both SQL and pandas match, indicating that the grouping, counting, filtering, and sorting operations have been performed consistently in both cases. This task demonstrates the equivalence of these operations in pandas and SQL.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9621051",
   "metadata": {},
   "source": [
    "### 13. SELECT manufacturer, COUNT(*) FROM planes\n",
    "### WHERE seats > 200 GROUP BY manufacturer HAVING COUNT(*) > 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ec27008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where seats > 200\n",
    "task13_my_filtered = planes[planes['seats'] > 200]\n",
    "\n",
    "# Group by 'manufacturer' and count the occurrences\n",
    "task13_my = task13_my_filtered.groupby('manufacturer').size().reset_index(name='count')\n",
    "\n",
    "# Filter rows where the count is greater than 10\n",
    "task13_my = task13_my[task13_my['count'] > 10]\n",
    "\n",
    "# Sort the DataFrame based on 'count' in descending order and 'manufacturer' in ascending order\n",
    "task13_my.sort_values(by=['count', 'manufacturer'], ascending=[False, True], inplace=True)\n",
    "\n",
    "# Reset index for consistent comparison\n",
    "task13_my.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Sort the 'planes' DataFrame from SQL query\n",
    "task13_sql_sorted = pd.read_sql_query(\"\"\"\n",
    "    SELECT manufacturer, COUNT(*) AS count\n",
    "    FROM planes\n",
    "    WHERE seats > 200\n",
    "    GROUP BY manufacturer\n",
    "    HAVING COUNT(*) > 10;\n",
    "\"\"\", conn).sort_values(by=['count', 'manufacturer'], ascending=[False, True]).reset_index(drop=True)\n",
    "\n",
    "# Perform the equality check\n",
    "pd.testing.assert_frame_equal(task13_sql_sorted, task13_my)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d768538a",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "Task 13 involves filtering rows in the 'planes' dataset where 'seats' > 200, grouping by 'manufacturer,' counting occurrences, filtering rows where the count is greater than 10, and sorting the result by count in descending order and 'manufacturer' in ascending order. Both pandas and SQL are used for this operation.\n",
    "\n",
    "Summary/Discussion:\n",
    "The results from both SQL and pandas match, indicating that the filtering, grouping, counting, and sorting operations have been performed consistently in both cases. This task demonstrates the equivalence of these operations in pandas and SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc88ef7",
   "metadata": {},
   "source": [
    "### 14. SELECT manufacturer, COUNT(*) AS howmany\n",
    "### FROM planes\n",
    "### GROUP BY manufacturer\n",
    "### ORDER BY howmany DESC LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "923c3cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'manufacturer' and count the occurrences\n",
    "task14_my = planes.groupby('manufacturer').size().reset_index(name='howmany')\n",
    "\n",
    "# Sort the DataFrame based on 'howmany' in descending order and 'manufacturer' in ascending order\n",
    "task14_my.sort_values(by=['howmany', 'manufacturer'], ascending=[False, True], inplace=True)\n",
    "\n",
    "# Retrieve the top 10 rows\n",
    "task14_my = task14_my.head(10)\n",
    "\n",
    "# Reset index for consistent comparison\n",
    "task14_my.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Sort the 'planes' DataFrame from SQL query\n",
    "task14_sql_sorted = pd.read_sql_query(\"\"\"\n",
    "    SELECT manufacturer, COUNT(*) AS howmany\n",
    "    FROM planes\n",
    "    GROUP BY manufacturer\n",
    "    ORDER BY howmany DESC\n",
    "    LIMIT 10;\n",
    "\"\"\", conn).sort_values(by=['howmany', 'manufacturer'], ascending=[False, True]).reset_index(drop=True)\n",
    "\n",
    "# Perform the equality check\n",
    "pd.testing.assert_frame_equal(task14_sql_sorted, task14_my)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3770a9",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "Task 14 involves grouping the 'planes' dataset by 'manufacturer,' counting occurrences, sorting the result by count in descending order and 'manufacturer' in ascending order, and retrieving the top 10 rows. Both pandas and SQL are used for this operation.\n",
    "\n",
    "Summary/Discussion:\n",
    "The results from both SQL and pandas match, indicating that the grouping, counting, sorting, and limiting operations have been performed consistently in both cases. This task demonstrates the equivalence of these operations in pandas and SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed44e4b2",
   "metadata": {},
   "source": [
    "### 15. SELECT\n",
    "### flights.*,\n",
    "### planes.year AS plane_year,\n",
    "### planes.speed AS plane_speed,\n",
    "### planes.seats AS plane_seats\n",
    "### FROM flights LEFT JOIN planes ON flights.tailnum=planes.tailnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c162df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mailv\\AppData\\Local\\Temp\\ipykernel_38292\\3097387301.py:30: FutureWarning: Mismatched null-like values None and nan found. In a future version, pandas equality-testing functions (e.g. assert_frame_equal) will consider these not-matching and raise.\n",
      "  pd.testing.assert_frame_equal(task15_sql_sorted, task15_my_sorted)\n"
     ]
    }
   ],
   "source": [
    "# Perform a left merge on 'flights' and 'planes' DataFrames\n",
    "merged_df = pd.merge(flights, planes[['tailnum', 'year', 'speed', 'seats']], on='tailnum', how='left')\n",
    "\n",
    "# Select the columns you need and rename them\n",
    "task15_my = merged_df[['year_x', 'month', 'day', 'dep_time', 'sched_dep_time', 'dep_delay',\n",
    "                        'arr_time', 'sched_arr_time', 'arr_delay', 'carrier', 'flight',\n",
    "                        'tailnum', 'origin', 'dest', 'air_time', 'distance', 'hour', 'minute',\n",
    "                        'time_hour', 'year_y', 'speed', 'seats']].rename(\n",
    "                            columns={'year_x': 'flights_year', 'year_y': 'plane_year', 'speed': 'plane_speed', 'seats': 'plane_seats'})\n",
    "\n",
    "# Sort both DataFrames based on a chosen column for consistent comparison\n",
    "task15_sql_sorted = pd.read_sql_query(\"\"\"\n",
    "    SELECT\n",
    "        flights.*,\n",
    "        planes.year AS plane_year,\n",
    "        planes.speed AS plane_speed,\n",
    "        planes.seats AS plane_seats\n",
    "    FROM flights\n",
    "    LEFT JOIN planes ON flights.tailnum=planes.tailnum;\n",
    "\"\"\", conn).sort_values(by='tailnum').reset_index(drop=True)\n",
    "\n",
    "# Rename the columns in task15_sql_sorted to match the column names in task15_my\n",
    "task15_sql_sorted = task15_sql_sorted.rename(\n",
    "    columns={'year': 'flights_year', 'speed': 'plane_speed', 'seats': 'plane_seats'}\n",
    ")\n",
    "\n",
    "task15_my_sorted = task15_my.sort_values(by='tailnum').reset_index(drop=True)\n",
    "\n",
    "# Perform the equality check\n",
    "pd.testing.assert_frame_equal(task15_sql_sorted, task15_my_sorted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e01128",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "Task 15 involves performing a left merge on 'flights' and 'planes' DataFrames based on the 'tailnum' column. After merging, specific columns are selected, and their names are renamed for consistency. Both pandas and SQL are used for this operation.\n",
    "\n",
    "Summary/Discussion:\n",
    "The results from both SQL and pandas match, indicating that the left merge, column selection, and renaming operations have been performed consistently in both cases. This task demonstrates the equivalence of these operations in pandas and SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb5953a",
   "metadata": {},
   "source": [
    "### 16. SELECT planes.*, airlines.* FROM\n",
    "### (SELECT DISTINCT carrier, tailnum FROM flights) AS cartail\n",
    "### INNER JOIN planes ON cartail.tailnum=planes.tailnum\n",
    "### INNER JOIN airlines ON cartail.carrier=airlines.carrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e32579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL query\n",
    "query = \"\"\"\n",
    "SELECT planes.*, airlines.* FROM\n",
    "(SELECT DISTINCT carrier, tailnum FROM flights) AS cartail\n",
    "INNER JOIN planes ON cartail.tailnum=planes.tailnum\n",
    "INNER JOIN airlines ON cartail.carrier=airlines.carrier;\n",
    "\"\"\"\n",
    "\n",
    "# Reading SQL query result into a pandas DataFrame\n",
    "task16_sql = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Sort the result for consistent comparison\n",
    "task16_sql_sorted = task16_sql.sort_values(by=['tailnum', 'carrier']).reset_index(drop=True)\n",
    "\n",
    "# pandas solution without SQL\n",
    "# Assuming DataFrame 'flights' with columns 'carrier' and 'tailnum'\n",
    "cartail = flights[['carrier', 'tailnum']].drop_duplicates()\n",
    "\n",
    "# Assuming DataFrames 'planes' and 'airlines' with columns 'tailnum' and 'carrier' respectively\n",
    "result_df = pd.merge(cartail, planes, on='tailnum', how='inner')\n",
    "result_df = pd.merge(result_df, airlines, on='carrier', how='inner')\n",
    "\n",
    "# Reorder columns to match the SQL result\n",
    "result_df = result_df[['tailnum', 'year', 'type', 'manufacturer', 'model', 'engines', 'seats',\n",
    "                       'speed', 'engine', 'carrier', 'name']]\n",
    "\n",
    "# Sort the result for consistent comparison\n",
    "result_df_sorted = result_df.sort_values(by=['tailnum', 'carrier']).reset_index(drop=True)\n",
    "\n",
    "# Perform the equality check\n",
    "pd.testing.assert_frame_equal(task16_sql_sorted, result_df_sorted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697b32de",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "Task 16 involves performing SQL joins in pandas without using SQL. The query retrieves unique pairs of 'carrier' and 'tailnum' from the 'flights' DataFrame, then performs inner joins with the 'planes' and 'airlines' DataFrames based on the specified conditions.\n",
    "\n",
    "Summary/Discussion:\n",
    "The results from both SQL and pandas match, indicating that the SQL joins have been successfully replicated using pandas without relying on SQL. This task demonstrates the equivalence of these operations in both approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a105441f",
   "metadata": {},
   "source": [
    "### 17. SELECT\n",
    "### flights2.*,\n",
    "### atemp,\n",
    "### ahumid\n",
    "### FROM (\n",
    "### SELECT * FROM flights WHERE origin='EWR'\n",
    "### ) AS flights2\n",
    "### LEFT JOIN (\n",
    "### SELECT\n",
    "### year, month, day,\n",
    "### AVG(temp) AS atemp,\n",
    "### AVG(humid) AS ahumid\n",
    "### FROM weather\n",
    "### WHERE origin='EWR'\n",
    "### GROUP BY year, month, day\n",
    "### ) AS weather2\n",
    "### ON flights2.year=weather2.year\n",
    "### AND flights2.month=weather2.month\n",
    "### AND flights2.day=weather2.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85c8f7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mailv\\AppData\\Local\\Temp\\ipykernel_38292\\525025734.py:39: FutureWarning: Mismatched null-like values None and nan found. In a future version, pandas equality-testing functions (e.g. assert_frame_equal) will consider these not-matching and raise.\n",
      "  pd.testing.assert_frame_equal(task17_sql_sorted, result_df.sort_values(by=['year', 'month', 'day']).reset_index(drop=True))\n"
     ]
    }
   ],
   "source": [
    "# SQL query\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    flights2.*,\n",
    "    atemp AS temp,\n",
    "    ahumid AS humid\n",
    "FROM (\n",
    "    SELECT * FROM flights WHERE origin='EWR'\n",
    ") AS flights2\n",
    "LEFT JOIN (\n",
    "    SELECT\n",
    "        year, month, day,\n",
    "        AVG(temp) AS atemp,\n",
    "        AVG(humid) AS ahumid\n",
    "    FROM weather\n",
    "    WHERE origin='EWR'\n",
    "    GROUP BY year, month, day\n",
    ") AS weather2\n",
    "ON flights2.year=weather2.year\n",
    "AND flights2.month=weather2.month\n",
    "AND flights2.day=weather2.day;\n",
    "\"\"\"\n",
    "\n",
    "# Reading SQL query result into a pandas DataFrame\n",
    "task17_sql = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Sort the result for consistent comparison\n",
    "task17_sql_sorted = task17_sql.sort_values(by=['year', 'month', 'day']).reset_index(drop=True)\n",
    "\n",
    "# pandas solution without SQL\n",
    "# Assuming DataFrames 'flights' and 'weather' with the required columns\n",
    "flights2 = flights[flights['origin'] == 'EWR']\n",
    "weather2 = weather[weather['origin'] == 'EWR'].groupby(['year', 'month', 'day']).agg({'temp': 'mean', 'humid': 'mean'}).reset_index()\n",
    "\n",
    "# Select only the necessary columns and rename them to match the SQL query\n",
    "result_df = pd.merge(flights2, weather2[['year', 'month', 'day', 'temp', 'humid']], on=['year', 'month', 'day'], how='left')\n",
    "\n",
    "# Perform the equality check\n",
    "pd.testing.assert_frame_equal(task17_sql_sorted, result_df.sort_values(by=['year', 'month', 'day']).reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dca567",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "Task 17 involves performing SQL joins with aggregation in pandas without using SQL. The query retrieves flights originating from 'EWR' and performs a left join with aggregated weather data based on 'year', 'month', and 'day'.\n",
    "\n",
    "Summary/Discussion:\n",
    "The results from both SQL and pandas match, indicating that the SQL joins with aggregation have been successfully replicated using pandas without relying on SQL. This task demonstrates the equivalence of these operations in both approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ee86a2",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this report, I addressed various tasks involving SQL queries and their equivalent implementations using pandas in a Jupyter notebook. The tasks covered a range of operations, including basic selects, aggregations, filtering, and joins. For each task, the provided SQL query was translated into pandas code, and the results were compared to ensure equivalence.\n",
    "\n",
    "The pandas code successfully replicated the SQL functionality across all tasks, validating the flexibility and power of pandas as a data manipulation tool. Throughout the analysis, the results from both approaches were consistently identical, indicating a successful translation of SQL queries into pandas operations.\n",
    "\n",
    "For future extensions, one could explore optimizing the pandas code for larger datasets or enhancing the analysis with additional features. Additionally, this notebook serves as a valuable reference for users transitioning between SQL and pandas, showcasing practical examples of how to achieve similar results in both environments.\n",
    "\n",
    "Overall, this exercise not only demonstrated the versatility of pandas for data manipulation but also provided a comprehensive guide for users familiar with SQL to leverage their skills in a pandas-based data analysis environment.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
